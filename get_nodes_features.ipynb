{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407501ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/main/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from math_support import graph_random_walk, convert_sequence_to_graph, compute_index_subsample, graph_random_walk_fixed_start\n",
    "from data_loader import read_data, perform_ttv_split\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a639319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def extract_features_for_classifier(nnet, xembed_numpy, sembed_numpy, ylabel_numpy, eglist, \n",
    "                                    idx_train, idx_valid, idx_test, \n",
    "                                    nbatch=64):\n",
    "    \"\"\"\n",
    "    Извлекает признаки для каждой вершины после message passing и разделяет их на train/val/test\n",
    "    Запускает random walk из каждой вершины, гарантируя включение всех вершин\n",
    "    \n",
    "    Параметры:\n",
    "    - nnet: Обученная модель Edge_Sheaf_NNet\n",
    "    - xembed_numpy: Исходные признаки вершин (numpy array)\n",
    "    - ylabel_numpy: Метки классов вершин (numpy array)\n",
    "    - eglist: Список рёбер графа\n",
    "    - idx_train: Индексы вершин обучающей выборки\n",
    "    - idx_valid: Индексы вершин валидационной выборки\n",
    "    - idx_test: Индексы вершин тестовой выборки\n",
    "    - nbatch: Размер батча для random walk\n",
    "    \n",
    "    Возвращает:\n",
    "    - features_dict: Словарь с разделенными признаками и метками\n",
    "    \"\"\"\n",
    "    # Переводим модель в режим оценки\n",
    "    nnet.eval()\n",
    "    \n",
    "    # Конвертируем в тензор, если нужно\n",
    "    if isinstance(xembed_numpy, np.ndarray):\n",
    "        xembed = torch.from_numpy(xembed_numpy).double()\n",
    "    else:\n",
    "        xembed = xembed_numpy.clone()\n",
    "\n",
    "    if isinstance(sembed_numpy, np.ndarray):\n",
    "        sembed = torch.from_numpy(sembed_numpy).double()\n",
    "    else:\n",
    "        sembed = sembed_numpy.clone()\n",
    "    \n",
    "    # Количество вершин\n",
    "    num_vertices = sembed.shape[0]\n",
    "    \n",
    "    # Тензоры для агрегации признаков\n",
    "    final_features = torch.zeros_like(xembed)\n",
    "    feature_counts = torch.zeros(num_vertices)\n",
    "    \n",
    "    # Запускаем random walk из каждой вершины\n",
    "    for start_vertex in tqdm(list(range(num_vertices))):\n",
    "        # print(f'Processing random walk starting from vertex {start_vertex+1}/{num_vertices}')\n",
    "        \n",
    "        # Генерируем random walk, начиная с указанной вершины\n",
    "        random_walk_data = graph_random_walk_fixed_start(eglist, nbatch, start_vertex)\n",
    "        \n",
    "        # Конвертируем в представление графа\n",
    "        wgraph_numpy, idx_node = convert_sequence_to_graph(random_walk_data)\n",
    "        wgraph = torch.from_numpy(wgraph_numpy).double()\n",
    "        \n",
    "        # Получаем индексы для train/valid/test из текущего подграфа\n",
    "        idx_subsample_train = compute_index_subsample(idx_node, idx_train)\n",
    "        idx_subsample_valid = compute_index_subsample(idx_node, idx_valid)\n",
    "        idx_subsample_test = compute_index_subsample(idx_node, idx_test)\n",
    "        \n",
    "        # Выполняем message passing для этого подграфа (для всех вершин)\n",
    "        with torch.no_grad():\n",
    "            subgraph_features = perform_message_passing(nnet, xembed, sembed, wgraph, idx_node)\n",
    "        \n",
    "        # Обновляем признаки для всех типов вершин в текущем подграфе\n",
    "        for subset_name, idx_subset in [\n",
    "            ('train', idx_subsample_train), \n",
    "            ('valid', idx_subsample_valid), \n",
    "            ('test', idx_subsample_test)\n",
    "        ]:\n",
    "            # Если есть вершины текущего типа в подграфе\n",
    "            if len(idx_subset) > 0:\n",
    "                # Для каждой вершины в текущем подмножестве\n",
    "                for local_idx in idx_subset:\n",
    "                    # Получаем глобальный индекс вершины\n",
    "                    global_idx = idx_node[local_idx]\n",
    "                    \n",
    "                    # Обновляем признаки и счетчик\n",
    "                    final_features[global_idx] += subgraph_features[local_idx]\n",
    "                    feature_counts[global_idx] += 1\n",
    "    \n",
    "    # Усредняем признаки для каждой вершины\n",
    "    for i in range(num_vertices):\n",
    "        if feature_counts[i] > 0:\n",
    "            final_features[i] /= feature_counts[i]\n",
    "        else:\n",
    "            # Оставляем исходные признаки, если вершина не была включена ни в один random walk\n",
    "            final_features[i] = sembed[i]\n",
    "            print(f\"Warning: Vertex {i} not included in any random walk. Using original features.\")\n",
    "    \n",
    "    # Конвертируем обратно в numpy для использования с классификаторами\n",
    "    final_features_np = final_features.detach().cpu().numpy()\n",
    "    \n",
    "    # Разделяем данные на train/val/test\n",
    "    features_dict = {\n",
    "        'features': final_features_np,  # Полный набор признаков для всех вершин\n",
    "        'labels': ylabel_numpy,         # Полный набор меток для всех вершин\n",
    "        \n",
    "        # Разделенные наборы\n",
    "        'train_features': final_features_np[idx_train],\n",
    "        'train_labels': ylabel_numpy[idx_train],\n",
    "        \n",
    "        'val_features': final_features_np[idx_valid],\n",
    "        'val_labels': ylabel_numpy[idx_valid],\n",
    "        \n",
    "        'test_features': final_features_np[idx_test],\n",
    "        'test_labels': ylabel_numpy[idx_test],\n",
    "        \n",
    "        # Индексы для справки\n",
    "        'idx_train': idx_train,\n",
    "        'idx_valid': idx_valid,\n",
    "        'idx_test': idx_test\n",
    "    }\n",
    "    \n",
    "    print(f\"Features extracted successfully\")\n",
    "    print(f\"Train set: {len(idx_train)} samples\")\n",
    "    print(f\"Validation set: {len(idx_valid)} samples\")\n",
    "    print(f\"Test set: {len(idx_test)} samples\")\n",
    "    \n",
    "    return features_dict\n",
    "\n",
    "def perform_message_passing(nnet, xembed, sembed, wgraph, idx_node):\n",
    "    \"\"\"\n",
    "    Выполняет message passing для преобразования признаков\n",
    "    \n",
    "    Параметры:\n",
    "    - nnet: Обученная модель Edge_Sheaf_NNet\n",
    "    - xembed: Признаки всех вершин\n",
    "    - wgraph: Матрица смежности для подграфа\n",
    "    - idx_node: Индексы вершин в подграфе\n",
    "    \n",
    "    Возвращает:\n",
    "    - Преобразованные признаки после message passing\n",
    "    \"\"\"\n",
    "    # Инициализируем признаки вершин для message passing\n",
    "    xmaped = sembed[idx_node].clone()\n",
    "    \n",
    "    # Количество вершин в подграфе\n",
    "    num_subgraph_vertices = len(idx_node)\n",
    "    \n",
    "    # Сохраняем рёбра для эффективной обработки\n",
    "    edge_indices = []\n",
    "    for i in range(num_subgraph_vertices):\n",
    "        for j in range(num_subgraph_vertices):\n",
    "            if wgraph[i, j] > 0:\n",
    "                edge_indices.append((i, j))\n",
    "    \n",
    "    # Итерации message passing\n",
    "    for conv_idx in range(nnet.nconv):\n",
    "        if len(edge_indices) > 0:\n",
    "            # Подготавливаем признаки источников и целей\n",
    "            source_indices = [i for i, j in edge_indices]\n",
    "            target_indices = [j for i, j in edge_indices]\n",
    "            \n",
    "            source_features = sembed[source_indices]\n",
    "            target_features = sembed[target_indices]\n",
    "            \n",
    "            # Вычисляем все матрицы рёбер одним батчем\n",
    "            # print('features shapes', source_features.shape, target_features.shape)\n",
    "            edge_matrices_batch = nnet.get_edge_matrix(source_features, target_features)\n",
    "            # print(\"edge_matrices_batch\", edge_matrices_batch.shape)\n",
    "            \n",
    "            # Инициализируем для message passing\n",
    "            new_xmaped = torch.zeros_like(xembed)\n",
    "            node_counts = torch.zeros(num_subgraph_vertices).to(xmaped.device)\n",
    "            \n",
    "            # Применяем матрицы рёбер к признакам источников\n",
    "            messages = torch.bmm(\n",
    "                edge_matrices_batch,\n",
    "                xembed[source_indices].unsqueeze(2)\n",
    "            ).squeeze(2)\n",
    "            \n",
    "            # Накапливаем сообщения\n",
    "            for idx, (i, j) in enumerate(edge_indices):\n",
    "                weight = wgraph[i, j]\n",
    "                new_xmaped[j:j+1, :] += weight * messages[idx:idx+1]\n",
    "                node_counts[j] += weight\n",
    "            \n",
    "            # Нормализуем по общему весу\n",
    "            for j in range(num_subgraph_vertices):\n",
    "                if node_counts[j] > 0:\n",
    "                    new_xmaped[j] /= node_counts[j]\n",
    "            \n",
    "            # Обновляем признаки вершин\n",
    "            xmaped = new_xmaped\n",
    "        else:\n",
    "            # Если ребер нет, признаки не изменяются\n",
    "            pass\n",
    "    \n",
    "    return xmaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a560cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_user_item_embedding\n",
      "ylabel.shape = (4230,)\n"
     ]
    }
   ],
   "source": [
    "xembed, eglist, ylabel, ylprob, xsvd = read_data(embedding_dimension=1,\n",
    "                                                 dataset_name='CiteSeer', eps=1.0e-6)\n",
    "print('ylabel.shape = ' + str(ylabel.shape))\n",
    "nsample = xembed.shape[0]\n",
    "idx_train, idx_ttest, idx_valid = perform_ttv_split(nsample, ftrain=0.6, fttest=0.2, fvalid=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2275fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_dimension 16\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [32:50<00:00,  2.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [36:23<00:00,  1.94it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [36:09<00:00,  1.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 8\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [31:54<00:00,  2.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [35:52<00:00,  1.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 8\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [32:12<00:00,  2.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 16\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [33:31<00:00,  2.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 16\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [33:12<00:00,  2.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 8\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [32:58<00:00,  2.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [35:49<00:00,  1.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [37:02<00:00,  1.90it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 16\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [33:01<00:00,  2.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n",
      "embedding_dimension 64\n",
      "compute_user_item_embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4230/4230 [35:33<00:00,  1.98it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted successfully\n",
      "Train set: 2538 samples\n",
      "Validation set: 846 samples\n",
      "Test set: 846 samples\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(\"/home/ubuntu/simulations_my_svd/nnet_folder\"):\n",
    "    model_path = f\"/home/ubuntu/simulations_my_svd/nnet_folder/{filename}\"\n",
    "\n",
    "    model = torch.load(model_path, map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "    dataset_name = filename.split('_')[2]\n",
    "    embedding_dimension = int(re.findall(r\"dime_(\\d+)\", filename)[0])\n",
    "    print(\"embedding_dimension\", embedding_dimension)\n",
    "    xembed, eglist, ylabel, ylprob, xsvd = read_data(embedding_dimension=embedding_dimension,\n",
    "                                                             dataset_name=dataset_name, eps=1.0e-6)\n",
    "\n",
    "    extracted_features_result = extract_features_for_classifier(model, xembed, xsvd, ylabel, eglist, \n",
    "                                        idx_train, idx_valid, idx_ttest, \n",
    "                                        nbatch=64)\n",
    "\n",
    "    folder_name = filename.split('.')[0]\n",
    "    os.makedirs(f\"/home/ubuntu/simulations_my_svd/classificator_features/{folder_name}\", exist_ok=True)\n",
    "\n",
    "    for key, arr in extracted_features_result.items():\n",
    "        np.save(f\"/home/ubuntu/simulations_my_svd/classificator_features/{folder_name}/{key}\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8d3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
